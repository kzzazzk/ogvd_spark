{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16297c8-1084-4f56-b001-bf51142fe8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/18 19:13:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/18 19:13:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import findspark\n",
    "import numpy as np\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"Ejercicio1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96fb2-7c57-4a67-abaf-f849420f4d73",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffcc2a0c-3b6d-45fb-93bf-d4f2cbc9a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile (filename): \n",
    "    '''Arguments: \n",
    "    filename – name of the spam dataset file \n",
    "    12 columns: 11 features/dimensions (X) + 1 column with labels (Y) \n",
    "    Y -- Train labels (0 if normal traffic, 1 if botnet)  \n",
    "    m rows: number of examples (m) \n",
    "    Returns: \n",
    "    An RDD containing the data of filename. Each example (row) of the file \n",
    "    corresponds to one RDD record. Each record of the RDD is a tuple (X,y).  \n",
    "    “X” is an array containing the 11 features (float number) of an example  \n",
    "    “y” is the 12th column of an example (integer 0/1) '''\n",
    "    result = sc.textFile(filename)\n",
    "    map_result = result.map(lambda row: [float(x) for x in row.split(\",\")])\n",
    "    rdd_xy = map_result.map(lambda row: (row[:11],row[11]))\n",
    "    return rdd_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa82973c-27ed-4fe9-b3d0-6810eb5a0e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([3545.3018916840147,\n",
       "   3198.0139469522546,\n",
       "   80.00015469454229,\n",
       "   1.0000019205086303,\n",
       "   444960086.4643011,\n",
       "   476.8073064086366,\n",
       "   12.999999992936175,\n",
       "   -7.710424743123667e-09,\n",
       "   87.00000148917339,\n",
       "   19099430.15956688,\n",
       "   2468368394.7593513],\n",
       "  0.0),\n",
       " ([-1.21308761436012e-06,\n",
       "   7.999989079213265,\n",
       "   65499.99887793755,\n",
       "   0.9999997452701503,\n",
       "   61.99988768910407,\n",
       "   69.99980788311223,\n",
       "   11.999999995904211,\n",
       "   -2.35688187855132e-08,\n",
       "   8.00000498340475,\n",
       "   2468369617.006896,\n",
       "   2468368392.7377276],\n",
       "  1.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba\n",
    "data=readFile(\"./botnet_reduced_10k_l.csv\")\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfb078c-f344-4a1e-945b-2cf44a09719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3545.3018916840147, 3198.0139469522546, 80.00015469454229, 1.0000019205086303, 444960086.4643011, 476.8073064086366, 12.999999992936175, -7.710424743123667e-09, 87.00000148917339, 19099430.15956688, 2468368394.7593513]]\n",
      "\n",
      "[(0, (3545.3018916840147, 12569165.503178252, 1)), (1, (3198.0139469522546, 10227293.204901138, 1)), (2, (80.00015469454229, 6400.024751150697, 1)), (3, (1.0000019205086303, 1.000003841020949, 1)), (4, (444960086.4643011, 1.979894785463183e+17, 1))]\n",
      "\n",
      "[(0, (12803754.219009735, 42093817354.54738, 10000))]\n",
      "\n",
      "[(0, (1280.3754219009734, np.float64(1603.1283524554865))), (2, (6731.840347965938, np.float64(16143.570758867212))), (4, (121275247.72856577, np.float64(231897601.15814963))), (6, (9.076034067369386, np.float64(5.298563791442084))), (8, (123.35245169147989, np.float64(90.51210108183089))), (10, (2265313681.7355, np.float64(1295737133.3017318))), (1, (21567.839327212547, np.float64(24184.80186045207))), (3, (60997.64689050441, np.float64(132772.42926971006))), (5, (15681843.675553748, np.float64(44314898.97700508))), (7, (1.8753065233820918, np.float64(2.096302756194286))), (9, (2123967949.925293, np.float64(723225092.7000036)))]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows_rdd = data.map(lambda line: line[0])\n",
    "print(rows_rdd.take(1))\n",
    "print()\n",
    "cols_rdd = rows_rdd.flatMap(lambda row: [(i, (x,x*x, 1)) for i, x in enumerate(row)])\n",
    "print(cols_rdd.take(5))\n",
    "print()\n",
    "group_rdd = cols_rdd.reduceByKey(lambda a,b:(a[0]+b[0],a[1]+b[1],a[2]+b[2]))\n",
    "print(group_rdd.take(1))\n",
    "print()\n",
    "mean_rdd = group_rdd.map(lambda t: (t[0],(t[1][0] / t[1][2], np.sqrt((t[1][1] / t[1][2]) - (t[1][0] / t[1][2])**2))))\n",
    "print(mean_rdd.collect())\n",
    "print()\n",
    "broadcast_var = sc.broadcast(dict(mean_rdd.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d6c0a9-984d-4b06-af1c-ebe2876955b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (RDD_Xy): \n",
    "    '''Arguments: \n",
    "    RDD_Xy is an RDD containing data examples. Each record of the RDD is a tuple \n",
    "    (X,y). \n",
    "    “X” is an array containing the 11 features (float number) of an example \n",
    "    “y” is the label of the example (integer 0/1)  \n",
    "    Returns: \n",
    "    An RDD rescaled to N(0,1) in each column (mean=0, standard deviation=1) '''\n",
    "    def map_normalize (RDD_Xy): \n",
    "        result = []\n",
    "        x, y = RDD_Xy\n",
    "        var = broadcast_var.value\n",
    "        for i, x in enumerate(x):\n",
    "             mean_aux, std_aux = var[i]\n",
    "             if(std_aux!=0):\n",
    "                 result.append((x - mean_aux)/std_aux)\n",
    "             else:\n",
    "                 result.append(0.0)\n",
    "        return result, y\n",
    "        \n",
    "    rdd_norm = RDD_Xy.map(map_normalize)\n",
    "    return rdd_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40e6f8f-8c68-48cf-bc3f-9c8cc16bf845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([np.float64(1.4128166757913607), np.float64(-0.7595607144625546), np.float64(-0.4120426820452796), np.float64(-0.45940747807420984), np.float64(1.3958093448107236), np.float64(-0.3538621824769221), np.float64(0.7405716114816884), np.float64(-0.8945780973436418), np.float64(-0.4016308291135645), np.float64(-2.9103919941544856), np.float64(0.15670980463949324)], 0.0), ([np.float64(-0.7986730576830795), np.float64(-0.8914623101952646), np.float64(3.640344469496744), np.float64(-0.45940747809059307), np.float64(-0.5229686944711893), np.float64(-0.35387136240303985), np.float64(0.551841224079898), np.float64(-0.8945781049085767), np.float64(-1.2744422605302952), np.float64(0.4762025966160194), np.float64(0.156709803079282)], 1.0)]\n"
     ]
    }
   ],
   "source": [
    "rdd_norm = normalize(data)\n",
    "print(rdd_norm.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f0c3d9-9369-4c18-85b2-98f3f3402f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (np.float64(1.737507915322567e-14), 1.0000000000000009)), (1, (np.float64(9.445244586459011e-15), 0.999999999999989)), (2, (np.float64(-1.3302070556164836e-14), 0.9999999999999883)), (3, (np.float64(2.3310064989345848e-14), 0.9999999999999803)), (4, (np.float64(-1.3432810419544694e-15), 0.9999999999999976)), (5, (np.float64(-4.6409098786170944e-15), 1.0000000000000069)), (6, (np.float64(1.645616976020392e-15), 0.999999999999988)), (7, (np.float64(-1.1839595970286609e-14), 1.000000000000001)), (8, (np.float64(3.481659405224491e-17), 0.99999999999998)), (9, (np.float64(2.1675106154361856e-14), 0.9999999999998741)), (10, (np.float64(-2.4653701302668196e-14), 1.0000000000000524))]\n"
     ]
    }
   ],
   "source": [
    "# QUITAR: COMPROBACION SI DA 1 PARA CADA INDICE LA SUMA\n",
    "import math\n",
    "# comprobar que cada columna queda ~ media 0 y std 1\n",
    "x_norm = rdd_norm.map(lambda xy: xy[0])\n",
    "\n",
    "check = (\n",
    "    x_norm\n",
    "    .flatMap(lambda row: [(i, (v, v*v, 1)) for i, v in enumerate(row)])\n",
    "    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1], a[2]+b[2]))\n",
    "    .mapValues(lambda t: (\n",
    "        t[0]/t[2],  # mean\n",
    "        math.sqrt(max((t[1]/t[2]) - (t[0]/t[2])**2, 0.0))  # std\n",
    "    ))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(sorted(check, key=lambda x: x[0]))\n",
    "# medias ~ 0, std ~ 1 (salvo redondeo numérico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37090126-db1a-46db-bab8-bdfa528f3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMERA PRUEBA TRAIN\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    if z >= 0:\n",
    "        ez = math.exp(-z)\n",
    "        return 1.0 / (1.0 + ez)\n",
    "    else:\n",
    "        ez = math.exp(z)\n",
    "        return ez / (1.0 + ez)\n",
    "\n",
    "def _sample_grad(xy, w, b):\n",
    "    X, y = xy\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    y = float(y)\n",
    "\n",
    "    z = float(np.dot(w, X) + b)\n",
    "    y_hat = sigmoid(z)\n",
    "    diff = y_hat - y\n",
    "\n",
    "    grad_w = diff * X      # vector (11,)\n",
    "    grad_b = diff          # escalar\n",
    "\n",
    "    loss = -(y * math.log(y_hat)+(1-y)*math.log(1-y_hat))\n",
    "    return (grad_w, grad_b, loss)\n",
    "\n",
    "def train(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    '''Arguments: \n",
    "    RDD_Xy --- RDD containing data examples. Each record of the RDD is a tuple \n",
    "    (X,y). \n",
    "    “X” is an array containing the 11 features (float number) of an example \n",
    "    “y” is the label of the example (integer 0/1)  \n",
    "    iterations -- number of iterations of the optimization loop \n",
    "    learning_rate -- learning rate of the gradient descent \n",
    "    lambda_reg – regularization rate: l2 es el que vamos a aplicar\n",
    "    \n",
    "    Returns: \n",
    "    A list or array containing the weights “w” and bias “b”\tat the end of the \n",
    "    training process'''\t\n",
    "\n",
    "    sc = RDD_Xy.context\n",
    "    data = RDD_Xy.cache()\n",
    "\n",
    "    m = data.count()\n",
    "    if m == 0:\n",
    "        raise ValueError(\"RDD_Xy vacío\")\n",
    "\n",
    "    k = len(data.first()[0])  # 11\n",
    "    #cost=[]\n",
    "    # inicialización\n",
    "    rng = np.random.default_rng(42)\n",
    "    w = rng.normal(0, 0.01, size=k).astype(np.float64)\n",
    "    b = float(rng.normal(0, 0.01))\n",
    "    for i in range(iterations):\n",
    "        bc_w = sc.broadcast(w)\n",
    "        bc_b = sc.broadcast(b)\n",
    "\n",
    "        # suma de gradientes por todo el dataset\n",
    "        sum_grad_w, sum_grad_b, sum_loss = data.map(\n",
    "            lambda xy: _sample_grad(xy, bc_w.value, bc_b.value)\n",
    "        ).reduce(\n",
    "            lambda a, c: (a[0] + c[0],a[1] + c[1], a[2] + c[2])\n",
    "        )\n",
    "\n",
    "        bc_w.unpersist()\n",
    "        bc_b.unpersist()\n",
    "\n",
    "        # promedio + L2\n",
    "        grad_w = (sum_grad_w / m) + (lambda_reg / k) * w   # si tu rúbrica usa /k\n",
    "        grad_b = (sum_grad_b / m)\n",
    "        \n",
    "        # update\n",
    "        w = w - learning_rate * grad_w\n",
    "        b = b - learning_rate * grad_b\n",
    "        reg_term = (lambda_reg / (2*k)) * float(np.dot(w,w))\n",
    "        J = (sum_loss / m ) + reg_term\n",
    "        #cost[i]=J\n",
    "        \n",
    "        print(f\"Loss en iteracion {i}: {J}\")\n",
    "\n",
    "    return [w, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd993d6-357d-4fd9-83b0-ea115c715ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (w, b, RDD_Xy): \n",
    "    '''Arguments: \n",
    "    w -- weights \n",
    "    b -- bias \n",
    "    RDD_Xy – RDD containing examples to be predicted  \n",
    "    Returns: \n",
    "    accuracy -- the number of predictions that are correct divided by the number         \n",
    "    of records (examples) in RDD_xy.  \n",
    "    Predict function can be used for predicting a single example'''\n",
    "    pred_ok = RDD_Xy.map(\n",
    "            lambda xy: 1 if predict(w, b, xy[0]) == int(xy[1]) else 0\n",
    "        )\n",
    "    \n",
    "    correct = pred_ok.reduce(lambda a, c: a + c)\n",
    "    total = RDD_Xy.count()\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8561e660-51f3-43ae-afe3-a4b1cc99cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (w, b, X): \n",
    "    '''Arguments: \n",
    "    w -- weights \n",
    "    b -- bias \n",
    "    X – Example to be predicted  \n",
    "     \n",
    "    Returns: \n",
    "    Y_pred – a value (0/1) corresponding to the prediction of X '''\n",
    "    threshold=0.5\n",
    "    z = float(np.dot(np.asarray(w, dtype=float), np.asarray(X, dtype=float)) + float(b))\n",
    "    p = sigmoid(z)\n",
    "    return 1 if p >= threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35bfac36-6c32-4dae-a41d-9ec2b6b44ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/18 19:13:57 WARN BlockManager: Task 43 already completed, not releasing lock for rdd_25_0\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss en iteracion 0: 1.1773034242148737\n",
      "Loss en iteracion 1: 0.3237438545305561\n",
      "Loss en iteracion 2: 0.5389194864123462\n",
      "Loss en iteracion 3: 0.3629788586171003\n",
      "Loss en iteracion 4: 0.5102610587597608\n",
      "Loss en iteracion 5: 0.36875847433671377\n",
      "Loss en iteracion 6: 0.4941290525559061\n",
      "Loss en iteracion 7: 0.37244209516993365\n",
      "Loss en iteracion 8: 0.4834929427127869\n",
      "Loss en iteracion 9: 0.3753502590459937\n",
      "Loss en iteracion 10: 0.47577420534518844\n",
      "Loss en iteracion 11: 0.37787589774353636\n",
      "Loss en iteracion 12: 0.4698760928829802\n",
      "Loss en iteracion 13: 0.38015241834542696\n",
      "Loss en iteracion 14: 0.4652373565093517\n",
      "Loss en iteracion 15: 0.38224327063321406\n",
      "Loss en iteracion 16: 0.46153221522031307\n",
      "Loss en iteracion 17: 0.3841895214635521\n",
      "Loss en iteracion 18: 0.45855503728238484\n",
      "Loss en iteracion 19: 0.386022742624327\n",
      "[array([-0.08318148, -0.37121413, -0.16567924, -0.1438316 , -0.61248303,\n",
      "        0.39552139,  0.09157951, -0.52443077,  0.23814446,  0.31961884,\n",
      "        0.22016539]), -0.06063726602567687]\n",
      "acc: 0.929666\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data=readFile(\"./botnet_tot_syn_l_3.csv\")\n",
    "# standarize\n",
    "data = normalize(data)\n",
    "\n",
    "ws = train(data,20,5,1.5)\n",
    "print(ws)\n",
    "w,b = ws\n",
    "acc = accuracy(w,b,data)\n",
    "print(\"acc:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14adb164-5110-45ec-8dce-1de21a3af803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30449b3-3e55-435e-accf-34c342d9f13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
