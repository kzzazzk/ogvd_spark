{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16297c8-1084-4f56-b001-bf51142fe8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import findspark\n",
    "import numpy as np\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"Practica1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac96fb2-7c57-4a67-abaf-f849420f4d73",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc2a0c-3b6d-45fb-93bf-d4f2cbc9a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile (filename): \n",
    "    '''Arguments: \n",
    "    filename – name of the spam dataset file \n",
    "    12 columns: 11 features/dimensions (X) + 1 column with labels (Y) \n",
    "    Y -- Train labels (0 if normal traffic, 1 if botnet)  \n",
    "    m rows: number of examples (m) \n",
    "    Returns: \n",
    "    An RDD containing the data of filename. Each example (row) of the file \n",
    "    corresponds to one RDD record. Each record of the RDD is a tuple (X,y).  \n",
    "    “X” is an array containing the 11 features (float number) of an example  \n",
    "    “y” is the 12th column of an example (integer 0/1) '''\n",
    "    result = sc.textFile(filename)\n",
    "    map_result = result.map(lambda row: [float(x) for x in row.split(\",\")])\n",
    "    rdd_xy = map_result.map(lambda row: (row[:11],row[11]))\n",
    "    return rdd_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82973c-27ed-4fe9-b3d0-6810eb5a0e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prueba\n",
    "data=readFile(\"./botnet_reduced_10k_l.csv\")\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb078c-f344-4a1e-945b-2cf44a09719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_rdd = data.map(lambda line: line[0])\n",
    "print(rows_rdd.take(1))\n",
    "cols_rdd = rows_rdd.flatMap(lambda row: [(i, (x,x*x, 1)) for i, x in enumerate(row)])\n",
    "print(cols_rdd.take(5))\n",
    "group_rdd = cols_rdd.reduceByKey(lambda a,b:(a[0]+b[0],a[1]+b[1],a[2]+b[2]))\n",
    "print(group_rdd.take(1))\n",
    "mean_rdd = group_rdd.map(lambda t: (t[0],(t[1][0] / t[1][2], np.sqrt((t[1][1] / t[1][2]) - (t[1][0] / t[1][2])**2))))\n",
    "print(mean_rdd.collect())\n",
    "\n",
    "broadcast_var = sc.broadcast(dict(mean_rdd.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6c0a9-984d-4b06-af1c-ebe2876955b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (RDD_Xy): \n",
    "    '''Arguments: \n",
    "    RDD_Xy is an RDD containing data examples. Each record of the RDD is a tuple \n",
    "    (X,y). \n",
    "    “X” is an array containing the 11 features (float number) of an example \n",
    "    “y” is the label of the example (integer 0/1)  \n",
    "    Returns: \n",
    "    An RDD rescaled to N(0,1) in each column (mean=0, standard deviation=1) '''\n",
    "    def map_normalize (RDD_Xy): \n",
    "        result = []\n",
    "        x, y = RDD_Xy\n",
    "        var = broadcast_var.value\n",
    "        for i, x in enumerate(x):\n",
    "             mean_aux, std_aux = var[i]\n",
    "             if(std_aux!=0):\n",
    "                 result.append((x - mean_aux)/std_aux)\n",
    "             else:\n",
    "                 result.append(0.0)\n",
    "        return result, y\n",
    "        \n",
    "    rdd_norm = RDD_Xy.map(map_normalize)\n",
    "    return rdd_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e6f8f-8c68-48cf-bc3f-9c8cc16bf845",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_norm = normalize(data)\n",
    "print(rdd_norm.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0c3d9-9369-4c18-85b2-98f3f3402f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUITAR: COMPROBACION SI DA 1 PARA CADA INDICE LA SUMA\n",
    "import math\n",
    "# comprobar que cada columna queda ~ media 0 y std 1\n",
    "x_norm = rdd_norm.map(lambda xy: xy[0])\n",
    "\n",
    "check = (\n",
    "    x_norm\n",
    "    .flatMap(lambda row: [(i, (v, v*v, 1)) for i, v in enumerate(row)])\n",
    "    .reduceByKey(lambda a,b: (a[0]+b[0], a[1]+b[1], a[2]+b[2]))\n",
    "    .mapValues(lambda t: (\n",
    "        t[0]/t[2],  # mean\n",
    "        math.sqrt(max((t[1]/t[2]) - (t[0]/t[2])**2, 0.0))  # std\n",
    "    ))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(sorted(check, key=lambda x: x[0]))\n",
    "# medias ~ 0, std ~ 1 (salvo redondeo numérico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37090126-db1a-46db-bab8-bdfa528f3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMERA PRUEBA TRAIN\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    if z >= 0:\n",
    "        ez = math.exp(-z)\n",
    "        return 1.0 / (1.0 + ez)\n",
    "    else:\n",
    "        ez = math.exp(z)\n",
    "        return ez / (1.0 + ez)\n",
    "\n",
    "def _sample_grad(xy, w, b):\n",
    "    X, y = xy\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    y = float(y)\n",
    "\n",
    "    z = float(np.dot(w, X) + b)\n",
    "    yhat = sigmoid(z)\n",
    "    diff = yhat - y\n",
    "\n",
    "    grad_w = diff * X      # vector (11,)\n",
    "    grad_b = diff          # escalar\n",
    "    return (grad_w, grad_b)\n",
    "\n",
    "def train(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      [w, b]  (w: np.array de 11, b: float)\n",
    "    \"\"\"\n",
    "    sc = RDD_Xy.context\n",
    "    data = RDD_Xy.cache()\n",
    "\n",
    "    m = data.count()\n",
    "    if m == 0:\n",
    "        raise ValueError(\"RDD_Xy vacío\")\n",
    "\n",
    "    k = len(data.first()[0])  # 11\n",
    "\n",
    "    # inicialización\n",
    "    rng = np.random.default_rng(42)\n",
    "    w = rng.normal(0, 0.01, size=k).astype(np.float64)\n",
    "    b = 0.0\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        bc_w = sc.broadcast(w)\n",
    "        bc_b = sc.broadcast(b)\n",
    "\n",
    "        # suma de gradientes por todo el dataset\n",
    "        sum_grad_w, sum_grad_b = data.map(\n",
    "            lambda xy: _sample_grad(xy, bc_w.value, bc_b.value)\n",
    "        ).reduce(\n",
    "            lambda a, c: (a[0] + c[0], a[1] + c[1])\n",
    "        )\n",
    "\n",
    "        bc_w.unpersist()\n",
    "        bc_b.unpersist()\n",
    "\n",
    "        # promedio + L2\n",
    "        grad_w = (sum_grad_w / m) + (lambda_reg / k) * w   # si tu rúbrica usa /k\n",
    "        grad_b = (sum_grad_b / m)\n",
    "\n",
    "        # update\n",
    "        w = w - learning_rate * grad_w\n",
    "        b = b - learning_rate * grad_b\n",
    "\n",
    "    return [w, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1303dd-4eb1-4ca7-9c45-6ed5ccbde24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (RDD_Xy, iterations, learning_rate, lambda_reg): \n",
    "    '''Arguments: \n",
    "    RDD_Xy --- RDD containing data examples. Each record of the RDD is a tuple \n",
    "    (X,y). \n",
    "    “X” is an array containing the 11 features (float number) of an example \n",
    "    “y” is the label of the example (integer 0/1)  \n",
    "    iterations -- number of iterations of the optimization loop \n",
    "    learning_rate -- learning rate of the gradient descent \n",
    "    lambda_reg – regularization rate: l2 es el que vamos a aplicar\n",
    "    \n",
    "    Returns: \n",
    "    A list or array containing the weights “w” and bias “b”\tat the end of the \n",
    "    training process'''\t\n",
    "\n",
    "    tuple_weigth_bias = (np.random.random(11), np.random.rand()) # ARRAY DONDE LOS 11 PRIMEROS ELEMENTOS SON LOS PESOS Y EL ULTIMO EL SESGO\n",
    "    broadcast_var = sc.broadcast(tuple_weigth_bias)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # DERIVADAS DE PESOS Y SESGO\n",
    "        ## el map recibe como parametro la fila (y hay un broadcast con el array de pesos y sesgo) y genera rdd_actualizacion = (indice, (peso, sesgo))\n",
    "        # el reduce_by_key recibe como parametro en el rdd (indice, (peso, sesgo)) y devuelve (indice, (media_pesos, media_sesgo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98def8fa-9e61-400d-a4e9-18f4892f4293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd993d6-357d-4fd9-83b0-ea115c715ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy (w, b, RDD_Xy): \n",
    "    '''Arguments: \n",
    "    w -- weights \n",
    "    b -- bias \n",
    "    RDD_Xy – RDD containing examples to be predicted  \n",
    "    Returns: \n",
    "    accuracy -- the number of predictions that are correct divided by the number         \n",
    "    of records (examples) in RDD_xy.  \n",
    "    Predict function can be used for predicting a single example'''\n",
    "    pred_ok = RDD_Xy.map(\n",
    "            lambda xy: 1 if predict(w, b, xy[0]) == int(xy[1]) else 0\n",
    "        )\n",
    "    \n",
    "        correct = pred_ok.reduce(lambda a, c: a + c)\n",
    "        total = RDD_Xy.count()\n",
    "        return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561e660-51f3-43ae-afe3-a4b1cc99cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (w, b, X): \n",
    "    '''Arguments: \n",
    "    w -- weights \n",
    "    b -- bias \n",
    "    X – Example to be predicted  \n",
    "     \n",
    "    Returns: \n",
    "    Y_pred – a value (0/1) corresponding to the prediction of X '''\n",
    "    threshold=0.5\n",
    "    z = float(np.dot(np.asarray(w, dtype=float), np.asarray(X, dtype=float)) + float(b))\n",
    "    p = sigmoid(z)\n",
    "    return 1 if p >= threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfac36-6c32-4dae-a41d-9ec2b6b44ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data=readFile(path)\n",
    "\n",
    "# standarize\n",
    "data = normalize(data)\n",
    "\n",
    "ws = train(data,nIter,learningRate)\n",
    "acc = accuracy(data,ws)\n",
    "print(\"acc:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d3b5b-eb9e-49d9-b56c-d73c5836edde",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d89a85-b208-4809-b0db-47dc01c02911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data=readFile(path)\n",
    "\n",
    "# standarize\n",
    "data = normalize(data)\n",
    "num_blocks_cv=10\n",
    "\n",
    "# shuffle rows and transform data, specifying the number of blocks\n",
    "data_cv = transform(data,num_blocks_cv)\n",
    "\n",
    "for i in range(num_blocks_cv):\n",
    "    tr_data,test_data=get_block_data(data_cv,i)\n",
    "    \n",
    "    ws = train(data,nIter,learningRate)\n",
    "    acc = accuracy(data,ws)\n",
    "    print(\"acc:\",acc)\n",
    "\n",
    "print(\"average acc:\" avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14adb164-5110-45ec-8dce-1de21a3af803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9f4b3-5743-46e4-8b1a-76bfc826ae7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
